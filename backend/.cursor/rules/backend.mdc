---
description: Backend architecture rules and constraints
alwaysApply: true
---

# Backend Architecture Rules

## Service Layer Architecture (MANDATORY)

**NEVER** put business logic directly in API route handlers. API routes MUST be thin wrappers that:
1. Parse and validate request parameters
2. Call service methods
3. Dispatch Dramatiq tasks for background processing
4. Map service exceptions to HTTP responses
5. Return serialized responses

### Service Layer Structure

```
app/services/
├── exceptions.py              # Base service exceptions (ServiceError, NotFoundError, ValidationError)
├── download/                  # Generic download service with proxy support
│   ├── config.py              # RetryConfig, constants (USER_AGENTS, etc.)
│   └── download_service.py    # DownloadService class
├── orders/                    # Domain: order management
│   ├── exceptions.py          # OrderNotFound, ImageNotFound, etc.
│   ├── order_service.py       # Order CRUD (uses @mercure_autotrack)
│   ├── image_service.py
│   ├── shopify_image_download_service.py  # Shopify image download (uses DownloadService)
│   └── shopify_sync_service.py    # Shopify order sync (uses @mercure_autotrack)
├── coloring/                  # Domain: image processing
│   ├── exceptions.py          # ColoringVersionNotFound, SvgVersionNotFound, etc.
│   ├── coloring_service.py
│   ├── coloring_generation_service.py  # RunPod processing (uses @mercure_autotrack)
│   ├── svg_generation_service.py       # Vectorizer.ai processing (uses @mercure_autotrack)
│   └── vectorizer_service.py
├── mercure/                   # Mercure SSE event publishing
│   ├── events.py              # Event classes (OrderUpdateEvent, ImageUpdateEvent, etc.)
│   └── publish_service.py     # MercurePublishService
├── storage/                   # S3 storage abstraction
│   ├── storage_service.py     # S3StorageService
│   └── paths.py               # OrderStoragePaths key generation
└── external/                  # Third-party API clients (all classes)
    ├── runpod.py              # RunPodService
    ├── shopify.py             # ShopifyService
    └── vectorizer.py          # VectorizerApiService
```

**ALL services MUST be classes.** No function-based services are allowed.

### Service Class Pattern

```python
class OrderService:
    def __init__(self, session: AsyncSession):
        self.session = session

    async def get_order(self, order_id: str) -> Order:
        """Business logic here, raises custom exceptions."""
        order = await self._fetch_order(order_id)  # order_id is ULID string
        if not order:
            raise OrderNotFound()
        return order
```

### API Route Pattern

```python
@router.get("/orders/{order_id}", response_model=OrderDetailResponse, operation_id="getOrder")
async def get_order(order_id: str, service: OrderServiceDep) -> OrderDetailResponse:
    try:
        order = await service.get_order(order_id)  # order_id is ULID string
        return OrderDetailResponse.from_model(order)
    except OrderNotFound:
        raise HTTPException(404, "Order not found")
```

### Operation IDs (MANDATORY)

**ALL** FastAPI endpoints MUST have explicit `operation_id` for clean SDK generation:

```python
@router.get("/orders/{order_id}", response_model=OrderDetailResponse, operation_id="getOrder")
```

Naming convention:
- GET single resource: `get{Resource}` (e.g., `getOrder`, `getOrderImage`)
- GET list: `list{Resources}` (e.g., `listOrders`, `listVersions`)
- POST action: `{action}{Resource}` (e.g., `syncOrder`, `generateImageColoring`)
- PUT update: `select{Resource}` (e.g., `selectVersion`)
- POST retry: `retry{Resource}` (e.g., `retryVersion`)

## Order ID and ULID (MANDATORY)

- `Order.id` is a ULID string stored as PostgreSQL UUID (16 bytes)
- **ALL** API paths use `order_id` (ULID), not `shopify_id`
- `Order.order_number` is the display value (e.g., `#1270` for Shopify, `#M1000` for manual)
- `Order.shopify_id` and `Order.shopify_order_number` are optional (for Shopify orders only)

```python
from ulid import ULID

# Generate new ULID
order_id = str(ULID())

# Custom SQLAlchemy type: app/models/types.py -> ULIDType
# Stores as UUID in PostgreSQL, presents as string in Python/API
```

## S3 Storage (MANDATORY)

### S3StorageService

```python
from app.services.storage.storage_service import S3StorageService
from app.services.storage.paths import OrderStoragePaths

storage = S3StorageService()
paths = OrderStoragePaths(order)

# Upload file
key = paths.original_image(line_item, image, "jpg")
file_ref = await storage.upload(upload_to=key, data=image_bytes, content_type="image/jpeg")

# Download file
data = await storage.download(file_ref)

# Get public URL
url = storage.get_public_url(file_ref)  # Uses S3_PUBLIC_URL (mandatory)
```

### S3ObjectRef (File References)

All file references use `S3ObjectRefData` stored as JSONB:

```python
from app.models.types import S3ObjectRef, S3ObjectRefData

class Image(SQLModel, table=True):
    file_ref: S3ObjectRefData | None = Field(
        default=None,
        sa_column=Column(S3ObjectRef, nullable=True)
    )
```

### OrderStoragePaths Key Generation

```python
from app.services.storage.paths import OrderStoragePaths

paths = OrderStoragePaths(order)
paths.original_image(line_item, image, "jpg")      # orders/{ulid}/items/{pos}/original/image_{pos}.jpg
paths.coloring_version(line_item, image, version)  # orders/{ulid}/items/{pos}/coloring/v{n}/image_{pos}.png
paths.svg_version(line_item, image, version)       # orders/{ulid}/items/{pos}/svg/v{n}/image_{pos}.svg
```

## External File Downloads (MANDATORY)

Use `DownloadService` for downloading files from external URLs:

```python
from app.services.download.download_service import DownloadService

# ALWAYS use as async context manager
async with DownloadService() as download_service:
    # Direct download (no proxy)
    data = await download_service.download(url)

    # With proxy fallback (recommended for external CDNs)
    data = await download_service.download(url, proxy_fallback=True)

    # With extra headers
    data = await download_service.download(
        url,
        extra_headers={"Referer": "https://example.com/"},
        proxy_fallback=True,
    )
```

**Features:**

- Configurable retries via `tenacity` (default: 3 attempts)
- Dynamic proxy discovery from `PROXY_N_*` environment variables
- Browser-like headers with deterministic User-Agent/Accept-Language per hostname
- SSL certificate support for MITM proxies (BrightData, etc.)

## AutoIncrementOnConflict (Race-Safe Sequences)

Use `AutoIncrementOnConflict` for auto-incrementing fields with race condition handling:

```python
from app.models.utils.auto_increment import AutoIncrementOnConflict
from app.models.order import LINE_ITEM_POSITION_CONSTRAINT

async for attempt in AutoIncrementOnConflict(
    session=self.session,
    model_class=LineItem,
    increment_column=LineItem.position,
    filter_columns={LineItem.order_id: order_id},
    constraint=LINE_ITEM_POSITION_CONSTRAINT,
):
    async with attempt:
        line_item = LineItem(order_id=order_id, position=attempt.value, ...)
        self.session.add(line_item)
        await self.session.flush()
```

This handles:
1. Calculates next value with `MAX(column) + 1`
2. Creates savepoint before insert
3. Retries on unique constraint violation
4. Rolls back to savepoint and recalculates on conflict

## RedisLock (Distributed Locking)

Use `RedisLock` for distributed locking across workers:

```python
from app.utils.redis_lock import RedisLock
```

### Context Manager (Mutex with Auto-Release)

For exclusive access where you need automatic cleanup:

```python
with RedisLock("my-lock", ttl=60) as lock:
    if not lock.acquired:
        logger.debug("Lock unavailable, skipping")
        return
    do_exclusive_work()  # Lock auto-released on exit
```

### One-Shot (Deduplication)

For deduplication where TTL handles expiration:

```python
if RedisLock("task:123", ttl=300).try_acquire_lock():
    dispatch_task()  # Lock NOT released, expires after TTL
```

**NEVER** use `try_acquire_lock()` when you need cleanup - use context manager instead.

## Dramatiq Tasks Architecture (MANDATORY)

Tasks MUST be thin wrappers that:
1. Set up database session via `task_db_session(bg_tasks=...)`
2. Call service methods for ALL business logic
3. Handle task-specific concerns (retries, timeouts)
4. Pass context (order_id, image_id) for Mercure auto-tracking

**NEVER** put business logic in tasks. If new logic is needed, add a service method first.

### Task Pattern (with Mercure Auto-Tracking)

```python
from app.tasks.utils.task_db import task_db_session
from app.tasks.utils.decorators import task_recover
from app.tasks.utils.background_tasks import BackgroundTasks, background_tasks

@task_recover(ColoringService.get_incomplete_versions)
@dramatiq.actor(max_retries=3, min_backoff=1000, max_backoff=60000)
def generate_coloring(
    coloring_version_id: int,
    *,
    order_id: str,      # Required for Mercure context
    image_id: int,      # Required for Mercure context
    is_recovery: bool = False,
) -> None:
    asyncio.run(
        _generate_coloring_async(
            coloring_version_id,
            order_id=order_id,
            image_id=image_id,
            is_recovery=is_recovery,
        )  # type: ignore[call-arg]
    )

@background_tasks(timeout=30)
async def _generate_coloring_async(
    coloring_version_id: int,
    *,
    order_id: str,
    image_id: int,
    is_recovery: bool = False,
    bg_tasks: BackgroundTasks,  # Injected by @background_tasks decorator
) -> None:
    async with task_db_session(bg_tasks=bg_tasks) as session:
        service = ColoringGenerationService(session=session, ...)
        # Service handles Mercure context and auto-publishing
        await service.process(
            coloring_version_id,
            order_id=order_id,
            image_id=image_id,
            is_recovery=is_recovery,
        )
```

### External API Calls

- **NEVER** call external APIs from FastAPI workers (Shopify, RunPod, Vectorizer)
- **ALL** external API calls MUST happen in Dramatiq tasks
- External services are classes that handle API calls (e.g., `RunPodService`, `VectorizerApiService`)
- Tasks instantiate services and handle orchestration and error handling

### Tasks Folder Structure

Tasks are organized to mirror the services structure:

```
app/tasks/
├── __init__.py              # Imports broker and registers all tasks
├── broker.py                # Redis broker configuration
├── utils/
│   ├── __init__.py          # Empty (docstring only)
│   ├── decorators.py        # @task_recover decorator
│   ├── recovery.py          # run_recovery task + recovery utilities
│   ├── task_db.py           # task_db_session context manager
│   └── background_tasks.py  # @background_tasks decorator
├── orders/                  # mirrors services/orders/
│   ├── __init__.py
│   ├── fetch_shopify_order.py # Batch fetch + single order ingestion
│   └── image_download.py      # Download/upload order images to S3
└── coloring/                # mirrors services/coloring/
    ├── __init__.py
    ├── generate_coloring.py
    └── vectorize_image.py
```

### Running Dramatiq Workers

Use the `uv run dramatiq-worker` script which handles recovery dispatch:

```bash
# Run with defaults
uv run dramatiq-worker

# Run with options (passed to dramatiq CLI)
uv run dramatiq-worker --processes 4 --threads 8

# Development with auto-reload
uv run dramatiq-worker --watch app
```

## Import Rules (MANDATORY)

### No Re-exports (HARD CONSTRAINT)

- **NEVER** re-export from `__init__.py` files - keep them empty (docstring only)
- **NEVER** create "backward compatibility" modules that only re-export from elsewhere
- **ALWAYS** use explicit imports from the actual module where code is defined
- Use `TYPE_CHECKING` imports for type hints that would cause circular imports

### Examples

```python
# BAD - importing from package __init__.py
from app.services import ColoringService

# GOOD - explicit imports from actual modules
from app.services.coloring.coloring_service import ColoringService
from app.utils.shopify_helpers import build_customer_name
from app.services.mercure.publish_service import MercurePublishService
from app.services.storage.storage_service import S3StorageService

# Storage service usage
storage = S3StorageService()
file_ref = await storage.upload(upload_to=key, data=data, content_type="image/png")

# Mercure (prefer auto-tracking, use legacy methods only during migration)
mercure = MercurePublishService()
await mercure.publish_order_update(order_id)  # DEPRECATED - prefer auto-tracking
```

## Custom Exceptions (MANDATORY)

**NEVER** raise `HTTPException` from service layer. Define typed exceptions in domain-specific exception files:

```python
# services/exceptions.py - base exceptions only
class ServiceError(Exception):
    """Base service exception."""

class NotFoundError(ServiceError):
    """Resource not found."""

class ValidationError(ServiceError):
    """Validation error."""

# services/orders/exceptions.py - order domain
from app.services.exceptions import NotFoundError, ValidationError

class OrderNotFound(NotFoundError):
    """Order not found."""

class ImageNotFound(NotFoundError):
    """Image not found."""
```

## Code Organization Rules

### Complex Logic MUST Be Split

When a file exceeds ~200 lines or contains multiple distinct concerns:
- Split into a **folder** with multiple files
- Keep `__init__.py` empty (docstring only)
- Group related functionality together

Example:
```
# BAD: Single 1000-line file
app/api/v1/orders.py

# GOOD: Organized folder structure
app/api/v1/orders/
├── __init__.py           # Empty (docstring only)
├── schemas.py            # Pydantic models
├── dependencies.py       # FastAPI dependencies
├── order_routes.py       # Order CRUD
├── image_routes.py       # Image endpoints
└── coloring_routes.py    # Coloring endpoints
```

### Helper Functions MUST Be Extracted

- **NEVER** duplicate logic across files
- Extract shared helpers to appropriate utility modules
- Use `app/utils/` for cross-cutting utilities
- Use service-specific `_helpers.py` for domain helpers

### Dependency Injection Pattern

Use FastAPI's `Depends` with type aliases:

```python
# dependencies.py
async def get_order_service(session: Annotated[AsyncSession, Depends(get_session)]) -> OrderService:
    return OrderService(session)

OrderServiceDep = Annotated[OrderService, Depends(get_order_service)]

# routes.py
@router.get("/orders")
async def list_orders(service: OrderServiceDep) -> list[OrderResponse]:
    ...
```

## Pydantic Schemas

### Use `from_model` Factory Methods

```python
class OrderResponse(BaseModel):
    id: str  # ULID string
    order_number: str  # Display value
    status: str

    @classmethod
    def from_model(cls, order: Order) -> "OrderResponse":
        return cls(id=order.id, order_number=order.order_number, status=order.status.value)
```

### Datetime Serialization

Use the shared timezone helper:

```python
from app.utils.datetime_utils import to_api_timezone

@field_serializer("created_at")
def serialize_dt(self, dt: datetime) -> str:
    return to_api_timezone(dt).isoformat()
```

## HTTP Method Guidelines

| Action | Method | Notes |
|--------|--------|-------|
| Read resource | GET | |
| Create resource | POST | |
| Update resource state | PUT | e.g., selecting a version |
| Trigger action | POST | e.g., retry, sync, generate |
| Delete resource | DELETE | |

## Database Queries

### Eager Loading

Always use `selectinload` for related objects to avoid N+1 queries:

```python
select(Order).options(
    selectinload(Order.line_items)
    .selectinload(LineItem.images)
)
```

## Mercure Auto-Tracking (MANDATORY)

Mercure events are automatically published via `TrackedAsyncSession` when tracked model fields change.

### Event Types (in `app/services/mercure/events.py`)

- `OrderUpdateEvent`: Triggered when `Order.status` changes
- `ImageUpdateEvent`: Triggered when `ColoringVersion.status`, `SvgVersion.status`, or `Image.selected_*_id` changes
- `ListUpdateEvent`: Batched event that collects `OrderUpdateEvent`s and emits when Orders are created/deleted

### Services with Tracked Field Changes

Services that modify tracked fields MUST:
1. Use `@mercure_autotrack(EventClass)` decorator
2. Have `session: TrackedAsyncSession` attribute
3. Call `session.set_mercure_context(...)` at start of public methods
4. Handle errors internally via private `_mark_error()` methods

```python
from app.db.mercure_protocol import mercure_autotrack
from app.db.tracked_session import TrackedAsyncSession
from app.models.order import Order, Image
from app.services.mercure.events import ImageUpdateEvent

@mercure_autotrack(ImageUpdateEvent)
class MyProcessingService:
    session: TrackedAsyncSession  # Required by MercureTrackable protocol
    
    def __init__(self, session: TrackedAsyncSession, ...):
        self.session = session
    
    async def process(self, version_id: int, *, order_id: str, image_id: int):
        # MUST be first line - sets context for Mercure event publishing
        self.session.set_mercure_context(Order.id == order_id, Image.id == image_id)  # type: ignore[arg-type]
        
        # ... tracked field changes (e.g., version.status = ...) 
        # ... auto-publish ImageUpdateEvent after commit
```

### Tasks with Order Status Changes

Tasks that modify `Order.status` MUST use `OrderService.update_status()`:

```python
async with task_db_session() as session:
    order_service = OrderService(session)
    
    # Update status via service (uses RecordLock, commits internally)
    await order_service.update_status(order_id, OrderStatus.PROCESSING)
```

**Tasks MUST NOT:**

- Call `session._track_changes()` directly (internal API)
- Call `session.set_mercure_context()` manually
- Modify `order.status` directly - always use service methods

### Task Context Requirements

Tasks dispatching to services with `@mercure_autotrack` MUST pass:
- `order_id: str` - Order ULID
- `image_id: int` - Image ID

```python
generate_coloring.send(version_id, order_id=order_id, image_id=image_id)
```

### Event Schema Exposure

The event schemas are exposed via `/api/v1/events/schema` endpoint for OpenAPI generation,
enabling type-safe frontend event handling through the generated SDK.

### API Routes (Manual Publishing)

API routes use regular `AsyncSession`, not `TrackedAsyncSession`. For API routes that need
to notify the frontend (e.g., version selection, queuing generation), publish events directly:

```python
from app.services.mercure.events import ImageUpdateEvent, ListUpdateEvent
from app.services.mercure.publish_service import MercurePublishService

# In API route
mercure = MercurePublishService()
await mercure.publish(ImageUpdateEvent(order_id=order_id, image_id=image_id))
await mercure.publish(ListUpdateEvent(order_ids=[]))  # Full refresh
```

### Bulk Operations (Batch Event Deferral)

When performing bulk operations with multiple commits, use `deferred_batch_events()` to batch
Mercure events into a single publish. This prevents flooding the frontend with many
individual events (e.g., 20 `ListUpdateEvent` messages instead of one batched message).

**Note:** Only events collected by a `BatchMercureEvent` are deferred (e.g., `OrderUpdateEvent`
is collected by `ListUpdateEvent`). Non-collected events like `ImageUpdateEvent` publish
immediately even during deferral.

```python
async with task_db_session() as session:
    async with session.deferred_batch_events():
        # Multiple commits happen here
        for item in items:
            await service.process(item)  # Each may commit
    # Single batched ListUpdateEvent published here
```

**MUST** use `deferred_batch_events()` context manager (not the private `_start_deferring_events()`) to ensure:
- Events are flushed on success
- Events are cleared on exception (no partial updates sent to frontend)

**Example use case:** `fetch_shopify_order.py` uses this to batch events when syncing multiple orders.

## Shopify Order Sync Architecture

### Service Responsibilities

- **OrderService** (uses `@mercure_autotrack(OrderUpdateEvent)`): Order CRUD, creation from Shopify/webhook data
  - `create_or_update_from_shopify()` - batch fetch order creation/update from GraphQL response
  - `get_or_create_from_webhook()` - webhook order creation from raw payload (idempotent)
  - `prepare_sync()` - reset order status for re-processing

- **ShopifySyncService** (uses `@mercure_autotrack(OrderUpdateEvent)`): Shopify API calls, LineItem/Image creation
  - `sync_single_order(order)` - fetch full order details from Shopify, create LineItems/Images
  - `sync_orders_batch(limit)` - orchestrates batch sync, calls `sync_single_order` for each order

### Sync Flows

**Webhook Flow** (single order, async via task):
1. Webhook endpoint → `OrderService.get_or_create_from_webhook()` → Order created
2. `ingest_order` task dispatched
3. Task creates `ShopifySyncService`, sets Mercure context
4. Task calls `sync_single_order(order)` → LineItems/Images created
5. `download_order_images` task dispatched if images need downloading
6. Mercure events auto-published on each commit

**Batch Fetch Flow** (multiple orders, sync within single task):
1. `fetch_orders_from_shopify` task starts
2. `ShopifySyncService.sync_orders_batch(limit)` called
3. For each Shopify order: `OrderService.create_or_update_from_shopify()` + `sync_single_order()`
4. `download_order_images` tasks dispatched for orders with images
5. Mercure events auto-published on each commit

**Manual Sync Flow** (re-process existing order):
1. API endpoint → `OrderService.prepare_sync()` → status reset to PENDING
2. `ingest_order` task dispatched
3. Same as webhook flow from step 3

### Key Points

- **No duplicate code**: `sync_orders_batch` reuses `sync_single_order` directly
- **Mercure auto-tracking**: Both services use `@mercure_autotrack(OrderUpdateEvent)`
- **ListUpdateEvent**: Auto-published when Orders are inserted (via `trigger_models` mechanism)
- **OrderUpdateEvent**: Auto-published when `Order.status` changes

## Services with @mercure_autotrack (MANDATORY)

**ALL services that modify tracked fields MUST use `@mercure_autotrack`:**

| Service | Event Type | Tracked Fields |
|---------|------------|----------------|
| `OrderService` | `OrderUpdateEvent` | `Order.status` |
| `ShopifySyncService` | `OrderUpdateEvent` | `Order.status` |
| `ColoringService` | `ImageUpdateEvent` | `ColoringVersion.status` |
| `VectorizerService` | `ImageUpdateEvent` | `SvgVersion.status` |
| `OrderImageService` | `ImageUpdateEvent` | `Image.selected_*_id` |
| `ColoringGenerationService` | `ImageUpdateEvent` | `ColoringVersion.status` |
| `SvgGenerationService` | `ImageUpdateEvent` | `SvgVersion.status` |

**Service Layer Structure with @mercure_autotrack:**

```
app/services/
├── orders/
│   ├── order_service.py        # @mercure_autotrack(OrderUpdateEvent)
│   ├── image_service.py        # @mercure_autotrack(ImageUpdateEvent)
│   └── shopify_sync_service.py # @mercure_autotrack(OrderUpdateEvent)
├── coloring/
│   ├── coloring_service.py     # @mercure_autotrack(ImageUpdateEvent)
│   ├── vectorizer_service.py   # @mercure_autotrack(ImageUpdateEvent)
│   ├── coloring_generation_service.py # @mercure_autotrack(ImageUpdateEvent)
│   └── svg_generation_service.py      # @mercure_autotrack(ImageUpdateEvent)
```

## RecordLock for Status Transitions (MANDATORY)

Status transition methods that may race with background tasks MUST use `RecordLock` (located in `app/db/processing_lock.py`):

```python
from app.db.processing_lock import RecordLock, RecordNotFoundError
from app.services.exceptions import UnexpectedStatusError

async def prepare_retry(self, version_id: int, *, order_id: str, image_id: int):
    # Set Mercure context FIRST
    self.session.set_mercure_context(Order.id == order_id, Image.id == image_id)
    
    lock = RecordLock(
        session=self.session,
        model_class=ColoringVersion,
        predicate=ColoringVersion.id == version_id,
    )
    
    try:
        async with lock:
            version = lock.record
            assert version is not None
            
            # Validate ownership INSIDE the lock (atomic)
            if version.image_id != image_id:
                raise VersionOwnershipError()
            
            # Verify status and update atomically using RecordLock helper
            await lock.verify_and_update_status(
                expected=ColoringProcessingStatus.ERROR,
                new_status=ColoringProcessingStatus.QUEUED,
            )
        
        await self.session.commit()
        return version
    except RecordNotFoundError:
        raise ColoringVersionNotFound()
    except UnexpectedStatusError:
        raise VersionNotInErrorState()
```

**Operations requiring RecordLock:**

- `ColoringService.prepare_retry()` - ERROR → QUEUED transition
- `VectorizerService.prepare_retry()` - ERROR → QUEUED transition
- `OrderService.prepare_sync()` - * → PENDING transition
- `OrderService.update_status()` - any Order.status transition (prevents race with user actions)

**Operations NOT requiring locking:**

- `select_*_version()` - idempotent (re-selecting is fine)
- `create_version()` - INSERT operations, no state machine

### HARD CONSTRAINT - Inside `async with lock:` block:

- **NEVER** modify tracked fields directly (e.g., `record.status = ...`)
- **NEVER** call `session.flush()` or `session.commit()` manually
- **ALWAYS** use RecordLock helper methods:
  - `lock.update_record(status=NewStatus)` - for simple updates
  - `lock.verify_and_update_status(expected, new_status)` - for validated transitions
- Commit AFTER the lock context exits: `await self.session.commit()`
- RecordLock raises `DirectModificationError` if you attempt direct modification inside the lock

## Testing Considerations

- Services are independently testable (inject mock session)
- API routes can be tested with TestClient
- Exceptions provide clear failure modes
