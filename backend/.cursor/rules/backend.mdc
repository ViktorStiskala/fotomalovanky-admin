---
description: Backend architecture rules and constraints
alwaysApply: true
---

# Backend Architecture Rules

## Service Layer Architecture (MANDATORY)

**NEVER** put business logic directly in API route handlers. API routes MUST be thin wrappers that:
1. Parse and validate request parameters
2. Call service methods
3. Dispatch Dramatiq tasks for background processing
4. Map service exceptions to HTTP responses
5. Return serialized responses

### Service Layer Structure

```
app/services/
├── exceptions.py              # Base service exceptions (ServiceError, NotFoundError, ValidationError)
├── download/                  # Generic download service with proxy support
│   ├── config.py              # RetryConfig, constants (USER_AGENTS, etc.)
│   └── download_service.py    # DownloadService class
├── orders/                    # Domain: order management
│   ├── exceptions.py          # OrderNotFound, ImageNotFound, etc.
│   ├── order_service.py
│   ├── image_service.py
│   ├── shopify_image_download_service.py  # Shopify image download (uses DownloadService)
│   └── shopify_sync_service.py    # Shopify order sync logic
├── coloring/                  # Domain: image processing
│   ├── exceptions.py          # ColoringVersionNotFound, SvgVersionNotFound, etc.
│   ├── coloring_service.py
│   ├── coloring_generation_service.py  # RunPod processing (uses @mercure_autotrack)
│   ├── svg_generation_service.py       # Vectorizer.ai processing (uses @mercure_autotrack)
│   └── vectorizer_service.py
├── mercure/                   # Mercure SSE event publishing
│   ├── events.py              # Event classes (OrderUpdateEvent, ImageUpdateEvent, etc.)
│   └── publish_service.py     # MercurePublishService
├── storage/                   # S3 storage abstraction
│   ├── storage_service.py     # S3StorageService
│   └── paths.py               # OrderStoragePaths key generation
└── external/                  # Third-party API clients (all classes)
    ├── runpod.py              # RunPodService
    ├── shopify.py             # ShopifyService
    └── vectorizer.py          # VectorizerApiService
```

**ALL services MUST be classes.** No function-based services are allowed.

### Service Class Pattern

```python
class OrderService:
    def __init__(self, session: AsyncSession):
        self.session = session

    async def get_order(self, order_id: str) -> Order:
        """Business logic here, raises custom exceptions."""
        order = await self._fetch_order(order_id)  # order_id is ULID string
        if not order:
            raise OrderNotFound()
        return order
```

### API Route Pattern

```python
@router.get("/orders/{order_id}", response_model=OrderDetailResponse, operation_id="getOrder")
async def get_order(order_id: str, service: OrderServiceDep) -> OrderDetailResponse:
    try:
        order = await service.get_order(order_id)  # order_id is ULID string
        return OrderDetailResponse.from_model(order)
    except OrderNotFound:
        raise HTTPException(404, "Order not found")
```

### Operation IDs (MANDATORY)

**ALL** FastAPI endpoints MUST have explicit `operation_id` for clean SDK generation:

```python
@router.get("/orders/{order_id}", response_model=OrderDetailResponse, operation_id="getOrder")
```

Naming convention:
- GET single resource: `get{Resource}` (e.g., `getOrder`, `getOrderImage`)
- GET list: `list{Resources}` (e.g., `listOrders`, `listVersions`)
- POST action: `{action}{Resource}` (e.g., `syncOrder`, `generateImageColoring`)
- PUT update: `select{Resource}` (e.g., `selectVersion`)
- POST retry: `retry{Resource}` (e.g., `retryVersion`)

## Order ID and ULID (MANDATORY)

- `Order.id` is a ULID string stored as PostgreSQL UUID (16 bytes)
- **ALL** API paths use `order_id` (ULID), not `shopify_id`
- `Order.order_number` is the display value (e.g., `#1270` for Shopify, `#M1000` for manual)
- `Order.shopify_id` and `Order.shopify_order_number` are optional (for Shopify orders only)

```python
from ulid import ULID

# Generate new ULID
order_id = str(ULID())

# Custom SQLAlchemy type: app/models/types.py -> ULIDType
# Stores as UUID in PostgreSQL, presents as string in Python/API
```

## S3 Storage (MANDATORY)

### S3StorageService

```python
from app.services.storage.storage_service import S3StorageService
from app.services.storage.paths import OrderStoragePaths

storage = S3StorageService()
paths = OrderStoragePaths(order)

# Upload file
key = paths.original_image(line_item, image, "jpg")
file_ref = await storage.upload(upload_to=key, data=image_bytes, content_type="image/jpeg")

# Download file
data = await storage.download(file_ref)

# Get public URL
url = storage.get_public_url(file_ref)  # Uses S3_PUBLIC_URL (mandatory)
```

### S3ObjectRef (File References)

All file references use `S3ObjectRefData` stored as JSONB:

```python
from app.models.types import S3ObjectRef, S3ObjectRefData

class Image(SQLModel, table=True):
    file_ref: S3ObjectRefData | None = Field(
        default=None,
        sa_column=Column(S3ObjectRef, nullable=True)
    )
```

### OrderStoragePaths Key Generation

```python
from app.services.storage.paths import OrderStoragePaths

paths = OrderStoragePaths(order)
paths.original_image(line_item, image, "jpg")      # orders/{ulid}/items/{pos}/original/image_{pos}.jpg
paths.coloring_version(line_item, image, version)  # orders/{ulid}/items/{pos}/coloring/v{n}/image_{pos}.png
paths.svg_version(line_item, image, version)       # orders/{ulid}/items/{pos}/svg/v{n}/image_{pos}.svg
```

## External File Downloads (MANDATORY)

Use `DownloadService` for downloading files from external URLs:

```python
from app.services.download.download_service import DownloadService

# ALWAYS use as async context manager
async with DownloadService() as download_service:
    # Direct download (no proxy)
    data = await download_service.download(url)

    # With proxy fallback (recommended for external CDNs)
    data = await download_service.download(url, proxy_fallback=True)

    # With extra headers
    data = await download_service.download(
        url,
        extra_headers={"Referer": "https://example.com/"},
        proxy_fallback=True,
    )
```

**Features:**

- Configurable retries via `tenacity` (default: 3 attempts)
- Dynamic proxy discovery from `PROXY_N_*` environment variables
- Browser-like headers with deterministic User-Agent/Accept-Language per hostname
- SSL certificate support for MITM proxies (BrightData, etc.)

## AutoIncrementOnConflict (Race-Safe Sequences)

Use `AutoIncrementOnConflict` for auto-incrementing fields with race condition handling:

```python
from app.models.utils.auto_increment import AutoIncrementOnConflict
from app.models.order import LINE_ITEM_POSITION_CONSTRAINT

async for attempt in AutoIncrementOnConflict(
    session=self.session,
    model_class=LineItem,
    increment_column=LineItem.position,
    filter_columns={LineItem.order_id: order_id},
    constraint=LINE_ITEM_POSITION_CONSTRAINT,
):
    async with attempt:
        line_item = LineItem(order_id=order_id, position=attempt.value, ...)
        self.session.add(line_item)
        await self.session.flush()
```

This handles:
1. Calculates next value with `MAX(column) + 1`
2. Creates savepoint before insert
3. Retries on unique constraint violation
4. Rolls back to savepoint and recalculates on conflict

## RedisLock (Distributed Locking)

Use `RedisLock` for distributed locking across workers:

```python
from app.utils.redis_lock import RedisLock
```

### Context Manager (Mutex with Auto-Release)

For exclusive access where you need automatic cleanup:

```python
with RedisLock("my-lock", ttl=60) as lock:
    if not lock.acquired:
        logger.debug("Lock unavailable, skipping")
        return
    do_exclusive_work()  # Lock auto-released on exit
```

### One-Shot (Deduplication)

For deduplication where TTL handles expiration:

```python
if RedisLock("task:123", ttl=300).try_acquire_lock():
    dispatch_task()  # Lock NOT released, expires after TTL
```

**NEVER** use `try_acquire_lock()` when you need cleanup - use context manager instead.

## Dramatiq Tasks Architecture (MANDATORY)

Tasks MUST be thin wrappers that:
1. Set up database session via `task_db_session(bg_tasks=...)`
2. Call service methods for ALL business logic
3. Handle task-specific concerns (retries, timeouts)
4. Pass context (order_id, image_id) for Mercure auto-tracking

**NEVER** put business logic in tasks. If new logic is needed, add a service method first.

### Task Pattern (with Mercure Auto-Tracking)

```python
from app.tasks.utils.task_db import task_db_session
from app.tasks.utils.decorators import task_recover
from app.tasks.utils.background_tasks import BackgroundTasks, background_tasks

@task_recover(ColoringService.get_incomplete_versions)
@dramatiq.actor(max_retries=3, min_backoff=1000, max_backoff=60000)
def generate_coloring(
    coloring_version_id: int,
    *,
    order_id: str,      # Required for Mercure context
    image_id: int,      # Required for Mercure context
    is_recovery: bool = False,
) -> None:
    asyncio.run(
        _generate_coloring_async(
            coloring_version_id,
            order_id=order_id,
            image_id=image_id,
            is_recovery=is_recovery,
        )  # type: ignore[call-arg]
    )

@background_tasks(timeout=30)
async def _generate_coloring_async(
    coloring_version_id: int,
    *,
    order_id: str,
    image_id: int,
    is_recovery: bool = False,
    bg_tasks: BackgroundTasks,  # Injected by @background_tasks decorator
) -> None:
    async with task_db_session(bg_tasks=bg_tasks) as session:
        service = ColoringGenerationService(session=session, ...)
        # Service handles Mercure context and auto-publishing
        await service.process(
            coloring_version_id,
            order_id=order_id,
            image_id=image_id,
            is_recovery=is_recovery,
        )
```

### External API Calls

- **NEVER** call external APIs from FastAPI workers (Shopify, RunPod, Vectorizer)
- **ALL** external API calls MUST happen in Dramatiq tasks
- External services are classes that handle API calls (e.g., `RunPodService`, `VectorizerApiService`)
- Tasks instantiate services and handle orchestration and error handling

### Tasks Folder Structure

Tasks are organized to mirror the services structure:

```
app/tasks/
├── __init__.py              # Imports broker and registers all tasks
├── broker.py                # Redis broker configuration
├── utils/
│   ├── __init__.py          # Empty (docstring only)
│   ├── decorators.py        # @task_recover decorator
│   ├── recovery.py          # run_recovery task + recovery utilities
│   ├── task_db.py           # task_db_session context manager
│   ├── background_tasks.py  # @background_tasks decorator
│   └── processing_lock.py   # RecordLock, ProcessingLock
├── orders/                  # mirrors services/orders/
│   ├── __init__.py
│   ├── fetch_shopify.py
│   ├── image_download.py
│   └── order_ingestion.py
└── coloring/                # mirrors services/coloring/
    ├── __init__.py
    ├── generate_coloring.py
    └── vectorize_image.py
```

### Running Dramatiq Workers

Use the `uv run dramatiq-worker` script which handles recovery dispatch:

```bash
# Run with defaults
uv run dramatiq-worker

# Run with options (passed to dramatiq CLI)
uv run dramatiq-worker --processes 4 --threads 8

# Development with auto-reload
uv run dramatiq-worker --watch app
```

## Import Rules (MANDATORY)

### No Re-exports (HARD CONSTRAINT)

- **NEVER** re-export from `__init__.py` files - keep them empty (docstring only)
- **NEVER** create "backward compatibility" modules that only re-export from elsewhere
- **ALWAYS** use explicit imports from the actual module where code is defined
- Use `TYPE_CHECKING` imports for type hints that would cause circular imports

### Examples

```python
# BAD - importing from package __init__.py
from app.services import ColoringService

# GOOD - explicit imports from actual modules
from app.services.coloring.coloring_service import ColoringService
from app.utils.shopify_helpers import build_customer_name
from app.services.mercure.publish_service import MercurePublishService
from app.services.storage.storage_service import S3StorageService

# Storage service usage
storage = S3StorageService()
file_ref = await storage.upload(upload_to=key, data=data, content_type="image/png")

# Mercure (prefer auto-tracking, use legacy methods only during migration)
mercure = MercurePublishService()
await mercure.publish_order_update(order_id)  # DEPRECATED - prefer auto-tracking
```

## Custom Exceptions (MANDATORY)

**NEVER** raise `HTTPException` from service layer. Define typed exceptions in domain-specific exception files:

```python
# services/exceptions.py - base exceptions only
class ServiceError(Exception):
    """Base service exception."""

class NotFoundError(ServiceError):
    """Resource not found."""

class ValidationError(ServiceError):
    """Validation error."""

# services/orders/exceptions.py - order domain
from app.services.exceptions import NotFoundError, ValidationError

class OrderNotFound(NotFoundError):
    """Order not found."""

class ImageNotFound(NotFoundError):
    """Image not found."""
```

## Code Organization Rules

### Complex Logic MUST Be Split

When a file exceeds ~200 lines or contains multiple distinct concerns:
- Split into a **folder** with multiple files
- Keep `__init__.py` empty (docstring only)
- Group related functionality together

Example:
```
# BAD: Single 1000-line file
app/api/v1/orders.py

# GOOD: Organized folder structure
app/api/v1/orders/
├── __init__.py           # Empty (docstring only)
├── schemas.py            # Pydantic models
├── dependencies.py       # FastAPI dependencies
├── order_routes.py       # Order CRUD
├── image_routes.py       # Image endpoints
└── coloring_routes.py    # Coloring endpoints
```

### Helper Functions MUST Be Extracted

- **NEVER** duplicate logic across files
- Extract shared helpers to appropriate utility modules
- Use `app/utils/` for cross-cutting utilities
- Use service-specific `_helpers.py` for domain helpers

### Dependency Injection Pattern

Use FastAPI's `Depends` with type aliases:

```python
# dependencies.py
async def get_order_service(session: Annotated[AsyncSession, Depends(get_session)]) -> OrderService:
    return OrderService(session)

OrderServiceDep = Annotated[OrderService, Depends(get_order_service)]

# routes.py
@router.get("/orders")
async def list_orders(service: OrderServiceDep) -> list[OrderResponse]:
    ...
```

## Pydantic Schemas

### Use `from_model` Factory Methods

```python
class OrderResponse(BaseModel):
    id: str  # ULID string
    order_number: str  # Display value
    status: str

    @classmethod
    def from_model(cls, order: Order) -> "OrderResponse":
        return cls(id=order.id, order_number=order.order_number, status=order.status.value)
```

### Datetime Serialization

Use the shared timezone helper:

```python
from app.utils.datetime_utils import to_api_timezone

@field_serializer("created_at")
def serialize_dt(self, dt: datetime) -> str:
    return to_api_timezone(dt).isoformat()
```

## HTTP Method Guidelines

| Action | Method | Notes |
|--------|--------|-------|
| Read resource | GET | |
| Create resource | POST | |
| Update resource state | PUT | e.g., selecting a version |
| Trigger action | POST | e.g., retry, sync, generate |
| Delete resource | DELETE | |

## Database Queries

### Eager Loading

Always use `selectinload` for related objects to avoid N+1 queries:

```python
select(Order).options(
    selectinload(Order.line_items)
    .selectinload(LineItem.images)
)
```

## Mercure Auto-Tracking (MANDATORY)

Mercure events are automatically published via `TrackedAsyncSession` when tracked model fields change.

### Event Types (in `app/services/mercure/events.py`)

- `OrderUpdateEvent`: Triggered when `Order.status` changes
- `ImageUpdateEvent`: Triggered when `ColoringVersion.status`, `SvgVersion.status`, or `Image.selected_*_id` changes
- `ListUpdateEvent`: Batched event that collects `OrderUpdateEvent`s and emits when Orders are created/deleted

### Services with Tracked Field Changes

Services that modify tracked fields MUST:
1. Use `@mercure_autotrack(EventClass)` decorator
2. Have `session: TrackedAsyncSession` attribute
3. Call `session.set_mercure_context(...)` at start of public methods
4. Handle errors internally via private `_mark_error()` methods

```python
from app.db.mercure_protocol import mercure_autotrack
from app.db.tracked_session import TrackedAsyncSession
from app.models.order import Order, Image
from app.services.mercure.events import ImageUpdateEvent

@mercure_autotrack(ImageUpdateEvent)
class MyProcessingService:
    session: TrackedAsyncSession  # Required by MercureTrackable protocol
    
    def __init__(self, session: TrackedAsyncSession, ...):
        self.session = session
    
    async def process(self, version_id: int, *, order_id: str, image_id: int):
        # MUST be first line - sets context for Mercure event publishing
        self.session.set_mercure_context(Order.id == order_id, Image.id == image_id)  # type: ignore[arg-type]
        
        # ... tracked field changes (e.g., version.status = ...) 
        # ... auto-publish ImageUpdateEvent after commit
```

### Tasks with Order Status Changes

Tasks that directly modify `Order.status` MUST:
1. Call `session.track_changes(Order.status)` at start
2. Call `session.set_mercure_context(Order.id == order_id)` at start

```python
async with task_db_session() as session:
    # Enable auto-tracking for Order.status changes
    session.track_changes(Order.status)  # type: ignore[arg-type]
    session.set_mercure_context(Order.id == order_id)  # type: ignore[arg-type]
    
    order.status = OrderStatus.PROCESSING  # Auto-published after commit
    await session.commit()
```

### Task Context Requirements

Tasks dispatching to services with `@mercure_autotrack` MUST pass:
- `order_id: str` - Order ULID
- `image_id: int` - Image ID

```python
generate_coloring.send(version_id, order_id=order_id, image_id=image_id)
```

### Event Schema Exposure

The event schemas are exposed via `/api/v1/events/schema` endpoint for OpenAPI generation,
enabling type-safe frontend event handling through the generated SDK.

### API Routes (Manual Publishing)

API routes use regular `AsyncSession`, not `TrackedAsyncSession`. For API routes that need
to notify the frontend (e.g., version selection, queuing generation), publish events directly:

```python
from app.services.mercure.events import ImageUpdateEvent, ListUpdateEvent
from app.services.mercure.publish_service import MercurePublishService

# In API route
mercure = MercurePublishService()
await mercure.publish(ImageUpdateEvent(order_id=order_id, image_id=image_id))
await mercure.publish(ListUpdateEvent(order_ids=[]))  # Full refresh
```

### Bulk Operations (Batch Event Deferral)

When performing bulk operations with multiple commits, use `deferred_batch_events()` to batch
Mercure events into a single publish. This prevents flooding the frontend with many
individual events (e.g., 20 `ListUpdateEvent` messages instead of one batched message).

**Note:** Only events collected by a `BatchMercureEvent` are deferred (e.g., `OrderUpdateEvent`
is collected by `ListUpdateEvent`). Non-collected events like `ImageUpdateEvent` publish
immediately even during deferral.

```python
async with task_db_session() as session:
    async with session.deferred_batch_events():
        # Multiple commits happen here
        for item in items:
            await service.process(item)  # Each may commit
    # Single batched ListUpdateEvent published here
```

**MUST** use `deferred_batch_events()` context manager (not the private `_start_deferring_events()`) to ensure:
- Events are flushed on success
- Events are cleared on exception (no partial updates sent to frontend)

**Example use case:** `fetch_shopify.py` uses this to batch events when syncing multiple orders.

## Testing Considerations

- Services are independently testable (inject mock session)
- API routes can be tested with TestClient
- Exceptions provide clear failure modes
